import pandas as pd

# Load the CSV 
df = pd.read_csv('/Users/WaleedAlzarooni/Desktop/winequality-red.csv')

file_path = '/Users/WaleedAlzarooni/Desktop/winequality-red.csv'

df = pd.read_csv(file_path, delimiter=';')

from sklearn.model_selection import train_test_split


X = df.drop(columns='quality')  
y = df['quality']               

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_train.shape, X_test.shape, y_train.shape, y_test.shape

import numpy as np
from sklearn.metrics import mean_squared_error

X_train_full = X_train.values  
y_train_full = y_train.values  

X_test_full = X_test.values 
y_test_full = y_test.values  

# Add bias
X_train_full_with_bias = np.c_[np.ones(X_train_full.shape[0]), X_train_full]
X_test_full_with_bias = np.c_[np.ones(X_test_full.shape[0]), X_test_full]

# Closed-form solution: w = (X^T X)^-1 X^T y
weights_full = np.linalg.inv(X_train_full_with_bias.T.dot(X_train_full_with_bias)).dot(X_train_full_with_bias.T).dot(y_train_full)

# Make predictions on the training set
y_train_pred_full = X_train_full_with_bias.dot(weights_full)

# Compute the sum-of-squares error on the training set
sse_full = np.sum((y_train_full - y_train_pred_full) ** 2)
print(f"Sum-of-squares error on training set: {sse_full}")

# Compute RMSE 
train_rmse = np.sqrt(mean_squared_error(y_train_full, y_train_pred_full))
print(f"Root Mean Squared Error (RMSE) on Training Set: {train_rmse}")

y_test_pred_full = X_test_full_with_bias.dot(weights_full)

test_rmse = np.sqrt(mean_squared_error(y_test_full, y_test_pred_full))
print(f"Root Mean Squared Error (RMSE) on Test Set: {test_rmse}")

import matplotlib.pyplot as plt
# Plot actual vs predicted values
plt.figure(figsize=(8, 6))
plt.scatter(y_train_full, y_train_pred_full, alpha=0.7, edgecolor='k')
plt.plot([y_train_full.min(), y_train_full.max()], [y_train_full.min(), y_train_full.max()], color='red', linewidth=2, linestyle='--')
plt.xlabel("Actual Target Values")
plt.ylabel("Predicted Target Values")
plt.title("Actual vs Predicted Target Values (Training Data)")
plt.grid(True)
plt.show()
print("we can see here that the training data generalises reasonably well to a linear model")

import numpy as np
from sklearn.metrics import mean_squared_error

# Hyperparameters
learning_rate = 0.0001  
n_iterations = 1000    

# Initialize weights
weights_lms = np.random.randn(X_train_full_with_bias.shape[1])
n_samples = X_train_full_with_bias.shape[0]

# LMS algorithm for updating weights
for iteration in range(n_iterations):

    indices = np.random.permutation(n_samples)
    
    for i in indices:
        
        x_n = X_train_full_with_bias[i]  
        y_n = y_train_full[i]           
        
      
        y_pred_n = np.dot(weights_lms, x_n)
        
    
        error_n = y_n - y_pred_n
        
       
        weights_lms += learning_rate * error_n * x_n  

   #monitor RMSE
    if iteration % 100 == 0:
        y_train_pred_lms = X_train_full_with_bias.dot(weights_lms)
        train_rmse_lms = np.sqrt(mean_squared_error(y_train_full, y_train_pred_lms))
        print(f"Iteration {iteration}: RMSE on Train Set: {train_rmse_lms}")

# Final weights after LMS updates
print(f"Final weights after LMS: {weights_lms}")

# Make predictions on the test set
y_test_pred_lms = X_test_full_with_bias.dot(weights_lms)

# Compute RMSE for the training set
train_rmse_lms = np.sqrt(mean_squared_error(y_train_full, y_train_pred_lms))
print(f"Root Mean Squared Error (RMSE) on Train Set: {train_rmse_lms}")

# Compute RMSE for the test set
test_rmse_lms = np.sqrt(mean_squared_error(y_test_full, y_test_pred_lms))
print(f"Root Mean Squared Error (RMSE) on Test Set: {test_rmse_lms}")
